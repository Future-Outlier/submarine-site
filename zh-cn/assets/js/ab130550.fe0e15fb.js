"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[861],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),u=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(l.Provider,{value:t},e.children)},_={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=u(n),m=a,d=c["".concat(l,".").concat(m)]||c[m]||_[m]||o;return n?r.createElement(d,s(s({ref:t},p),{},{components:n})):r.createElement(d,s({ref:t},p))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=c;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:a,s[1]=i;for(var u=2;u<o;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}c.displayName="MDXCreateElement"},1881:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return i},metadata:function(){return u},toc:function(){return _}});var r=n(7462),a=n(3366),o=(n(7294),n(3905)),s=["components"],i={},l=void 0,u={unversionedId:"userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1/README",id:"version-0.6.0/userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1/README",title:"README",description:"\x3c!--",source:"@site/versioned_docs/version-0.6.0/userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1/README.md",sourceDirName:"userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1",slug:"/userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1/",permalink:"/zh-cn/docs/0.6.0/userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1/",editUrl:"https://github.com/apache/submarine/edit/master/website/versioned_docs/version-0.6.0/userDocs/yarn/docker/tensorflow/with-cifar10-models/ubuntu-18.04/cifar10_estimator_tf_1.13.1/README.md",tags:[],version:"0.6.0",frontMatter:{}},p={},_=[{value:"Prerequisite",id:"prerequisite",level:2},{value:"Training on a single machine with GPUs or CPU",id:"training-on-a-single-machine-with-gpus-or-cpu",level:2},{value:"Run distributed training",id:"run-distributed-training",level:2},{value:"(Optional) Running on Google Cloud Machine Learning Engine",id:"optional-running-on-google-cloud-machine-learning-engine",level:3},{value:"Set TF_CONFIG",id:"set-tf_config",level:3},{value:"Running script",id:"running-script",level:3},{value:"Master",id:"master",level:4},{value:"Worker",id:"worker",level:4},{value:"PS",id:"ps",level:4},{value:"Visualizing results with TensorBoard",id:"visualizing-results-with-tensorboard",level:2},{value:"Warnings",id:"warnings",level:2}],c={toc:_};function m(e){var t=e.components,n=(0,a.Z)(e,s);return(0,o.kt)("wrapper",(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"(Copied from ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator"},"https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator"),")"),(0,o.kt)("p",null,"CIFAR-10 is a common benchmark in machine learning for image recognition."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"http://www.cs.toronto.edu/~kriz/cifar.html"},"http://www.cs.toronto.edu/~kriz/cifar.html")),(0,o.kt)("p",null,"Code in this directory focuses on how to use TensorFlow Estimators to train and\nevaluate a CIFAR-10 ResNet model on:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"A single host with one CPU;"),(0,o.kt)("li",{parentName:"ul"},"A single host with multiple GPUs;"),(0,o.kt)("li",{parentName:"ul"},"Multiple hosts with CPU or multiple GPUs;")),(0,o.kt)("p",null,"Before trying to run the model we highly encourage you to read all the README."),(0,o.kt)("h2",{id:"prerequisite"},"Prerequisite"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/install/"},"Install")," TensorFlow version 1.2.1 or\nlater.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Download the CIFAR-10 dataset and generate TFRecord files using the provided\nscript.  The script and associated command below will download the CIFAR-10\ndataset and then generate a TFRecord for the training, validation, and\nevaluation datasets."))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python generate_cifar10_tfrecords.py --data-dir=${PWD}/cifar-10-data\n")),(0,o.kt)("p",null,"After running the command above, you should see the following files in the\n--data-dir (",(0,o.kt)("inlineCode",{parentName:"p"},"ls -R cifar-10-data"),"):"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"train.tfrecords"),(0,o.kt)("li",{parentName:"ul"},"validation.tfrecords"),(0,o.kt)("li",{parentName:"ul"},"eval.tfrecords")),(0,o.kt)("h2",{id:"training-on-a-single-machine-with-gpus-or-cpu"},"Training on a single machine with GPUs or CPU"),(0,o.kt)("p",null,"Run the training on CPU only. After training, it runs the evaluation."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"python cifar10_main.py --data-dir=${PWD}/cifar-10-data \\\n                       --job-dir=/tmp/cifar10 \\\n                       --num-gpus=0 \\\n                       --train-steps=1000\n")),(0,o.kt)("p",null,"Run the model on 2 GPUs using CPU as parameter server. After training, it runs\nthe evaluation."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"python cifar10_main.py --data-dir=${PWD}/cifar-10-data \\\n                       --job-dir=/tmp/cifar10 \\\n                       --num-gpus=2 \\\n                       --train-steps=1000\n")),(0,o.kt)("p",null,"Run the model on 2 GPUs using GPU as parameter server.\nIt will run an experiment, which for local setting basically means it will run\nstop training\na couple of times to perform evaluation."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"python cifar10_main.py --data-dir=${PWD}/cifar-10-data \\\n                       --job-dir=/tmp/cifar10 \\\n                       --variable-strategy GPU \\\n                       --num-gpus=2 \\\n")),(0,o.kt)("p",null,"There are more command line flags to play with; run\n",(0,o.kt)("inlineCode",{parentName:"p"},"python cifar10_main.py --help")," for details."),(0,o.kt)("h2",{id:"run-distributed-training"},"Run distributed training"),(0,o.kt)("h3",{id:"optional-running-on-google-cloud-machine-learning-engine"},"(Optional) Running on Google Cloud Machine Learning Engine"),(0,o.kt)("p",null,"This example can be run on Google Cloud Machine Learning Engine (ML Engine),\nwhich will configure the environment and take care of running workers,\nparameters servers, and masters in a fault tolerant way."),(0,o.kt)("p",null,"To install the command line tool, and set up a project and billing, see the\nquickstart ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.google.com/ml-engine/docs/quickstarts/command-line"},"here"),"."),(0,o.kt)("p",null,"You'll also need a Google Cloud Storage bucket for the data. If you followed the\ninstructions above, you can just run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"MY_BUCKET=gs://<my-bucket-name>\ngsutil cp -r ${PWD}/cifar-10-data $MY_BUCKET/\n")),(0,o.kt)("p",null,"Then run the following command from the ",(0,o.kt)("inlineCode",{parentName:"p"},"tutorials/image")," directory of this\nrepository (the parent directory of this README):"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"gcloud ml-engine jobs submit training cifarmultigpu \\\n    --runtime-version 1.2 \\\n    --job-dir=$MY_BUCKET/model_dirs/cifarmultigpu \\\n    --config cifar10_estimator/cmle_config.yaml \\\n    --package-path cifar10_estimator/ \\\n    --module-name cifar10_estimator.cifar10_main \\\n    -- \\\n    --data-dir=$MY_BUCKET/cifar-10-data \\\n    --num-gpus=4 \\\n    --train-steps=1000\n")),(0,o.kt)("h3",{id:"set-tf_config"},"Set TF_CONFIG"),(0,o.kt)("p",null,"Considering that you already have multiple hosts configured, all you need is a\n",(0,o.kt)("inlineCode",{parentName:"p"},"TF_CONFIG")," environment variable on each host. You can set up the hosts manually\nor check ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/tensorflow/ecosystem"},"tensorflow/ecosystem")," for\ninstructions about how to set up a Cluster."),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"TF_CONFIG")," will be used by the ",(0,o.kt)("inlineCode",{parentName:"p"},"RunConfig")," to know the existing hosts and\ntheir task: ",(0,o.kt)("inlineCode",{parentName:"p"},"master"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"ps")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"worker"),"."),(0,o.kt)("p",null,"Here's an example of ",(0,o.kt)("inlineCode",{parentName:"p"},"TF_CONFIG"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"cluster = {'master': ['master-ip:8000'],\n           'ps': ['ps-ip:8000'],\n           'worker': ['worker-ip:8000']}\n\nTF_CONFIG = json.dumps(\n  {'cluster': cluster,\n   'task': {'type': master, 'index': 0},\n   'model_dir': 'gs://<bucket_path>/<dir_path>',\n   'environment': 'cloud'\n  })\n")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Cluster")),(0,o.kt)("p",null,"A cluster spec, which is basically a dictionary that describes all of the tasks\nin the cluster. More about it ",(0,o.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/deploy/distributed"},"here"),"."),(0,o.kt)("p",null,"In this cluster spec we are defining a cluster with 1 master, 1 ps and 1 worker."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"ps"),": saves the parameters among all workers. All workers can\nread/write/update the parameters for model via ps. As some models are\nextremely large the parameters are shared among the ps (each ps stores a\nsubset).")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"worker"),": does the training.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("inlineCode",{parentName:"p"},"master"),": basically a special worker, it does training, but also restores and\nsaves checkpoints and do evaluation."))),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Task")),(0,o.kt)("p",null,"The Task defines what is the role of the current node, for this example the node\nis the master on index 0 on the cluster spec, the task will be different for\neach node. An example of the ",(0,o.kt)("inlineCode",{parentName:"p"},"TF_CONFIG")," for a worker would be:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"cluster = {'master': ['master-ip:8000'],\n           'ps': ['ps-ip:8000'],\n           'worker': ['worker-ip:8000']}\n\nTF_CONFIG = json.dumps(\n  {'cluster': cluster,\n   'task': {'type': worker, 'index': 0},\n   'model_dir': 'gs://<bucket_path>/<dir_path>',\n   'environment': 'cloud'\n  })\n")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Model_dir")),(0,o.kt)("p",null,"This is the path where the master will save the checkpoints, graph and\nTensorBoard files. For a multi host environment you may want to use a\nDistributed File System, Google Storage and DFS are supported."),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Environment")),(0,o.kt)("p",null,"By the default environment is ",(0,o.kt)("em",{parentName:"p"},"local"),", for a distributed setting we need to\nchange it to ",(0,o.kt)("em",{parentName:"p"},"cloud"),"."),(0,o.kt)("h3",{id:"running-script"},"Running script"),(0,o.kt)("p",null,"Once you have a ",(0,o.kt)("inlineCode",{parentName:"p"},"TF_CONFIG")," configured properly on each host you're ready to run\non distributed settings."),(0,o.kt)("h4",{id:"master"},"Master"),(0,o.kt)("p",null,"Run this on master:\nRuns an Experiment in sync mode on 4 GPUs using CPU as parameter server for\n40000 steps. It will run evaluation a couple of times during training. The\nnum_workers argument is used only to update the learning rate correctly. Make\nsure the model_dir is the same as defined on the TF_CONFIG."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python cifar10_main.py --data-dir=gs://path/cifar-10-data \\\n                       --job-dir=gs://path/model_dir/ \\\n                       --num-gpus=4 \\\n                       --train-steps=40000 \\\n                       --sync \\\n                       --num-workers=2\n")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Output:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"INFO:tensorflow:Using model_dir in TF_CONFIG: gs://path/model_dir/\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 1, '_keep_checkpoint_max': 5, '_task_type': u'master', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd16fb2be10>, '_model_dir': 'gs://path/model_dir/', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': intra_op_parallelism_threads: 1\ngpu_options {\n}\nallow_soft_placement: true\n, '_tf_random_seed': None, '_environment': u'cloud', '_num_worker_replicas': 1, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n  per_process_gpu_memory_fraction: 1.0\n}\n, '_evaluation_master': '', '_master': u'grpc://master-ip:8000'}\n...\n2017-08-01 19:59:26.496208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:00:04.0\nTotal memory: 11.17GiB\nFree memory: 11.09GiB\n2017-08-01 19:59:26.775660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:00:05.0\nTotal memory: 11.17GiB\nFree memory: 11.10GiB\n...\n2017-08-01 19:59:29.675171: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:8000\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 32, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\nINFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=1; total_num_replicas=1\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Restoring parameters from gs://path/model_dir/model.ckpt-0\n2017-08-01 19:59:37.560775: I tensorflow/core/distributed_runtime/master_session.cc:999] Start master session 156fcb55fe6648d6 with config:\nintra_op_parallelism_threads: 1\ngpu_options {\n  per_process_gpu_memory_fraction: 1\n}\nallow_soft_placement: true\n\nINFO:tensorflow:Saving checkpoints for 1 into gs://path/model_dir/model.ckpt.\nINFO:tensorflow:loss = 1.20682, step = 1\nINFO:tensorflow:loss = 1.20682, learning_rate = 0.1\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 32, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\nINFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=2; total_num_replicas=2\nINFO:tensorflow:Starting evaluation at 2017-08-01-20:00:14\n2017-08-01 20:00:15.745881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)\n2017-08-01 20:00:15.745949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0)\n2017-08-01 20:00:15.745958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:06.0)\n2017-08-01 20:00:15.745964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:07.0)\n2017-08-01 20:00:15.745969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:4) -> (device: 4, name: Tesla K80, pci bus id: 0000:00:08.0)\n2017-08-01 20:00:15.745975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:5) -> (device: 5, name: Tesla K80, pci bus id: 0000:00:09.0)\n2017-08-01 20:00:15.745987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:6) -> (device: 6, name: Tesla K80, pci bus id: 0000:00:0a.0)\n2017-08-01 20:00:15.745997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:7) -> (device: 7, name: Tesla K80, pci bus id: 0000:00:0b.0)\nINFO:tensorflow:Restoring parameters from gs://path/model_dir/model.ckpt-10023\nINFO:tensorflow:Evaluation [1/100]\nINFO:tensorflow:Evaluation [2/100]\nINFO:tensorflow:Evaluation [3/100]\nINFO:tensorflow:Evaluation [4/100]\nINFO:tensorflow:Evaluation [5/100]\nINFO:tensorflow:Evaluation [6/100]\nINFO:tensorflow:Evaluation [7/100]\nINFO:tensorflow:Evaluation [8/100]\nINFO:tensorflow:Evaluation [9/100]\nINFO:tensorflow:Evaluation [10/100]\nINFO:tensorflow:Evaluation [11/100]\nINFO:tensorflow:Evaluation [12/100]\nINFO:tensorflow:Evaluation [13/100]\n...\nINFO:tensorflow:Evaluation [100/100]\nINFO:tensorflow:Finished evaluation at 2017-08-01-20:00:31\nINFO:tensorflow:Saving dict for global step 1: accuracy = 0.0994, global_step = 1, loss = 630.425\n")),(0,o.kt)("h4",{id:"worker"},"Worker"),(0,o.kt)("p",null,"Run this on worker:\nRuns an Experiment in sync mode on 4 GPUs using CPU as parameter server for\n40000 steps. It will run evaluation a couple of times during training. Make sure\nthe model_dir is the same as defined on the TF_CONFIG."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python cifar10_main.py --data-dir=gs://path/cifar-10-data \\\n                       --job-dir=gs://path/model_dir/ \\\n                       --num-gpus=4 \\\n                       --train-steps=40000 \\\n                       --sync\n")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Output:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"INFO:tensorflow:Using model_dir in TF_CONFIG: gs://path/model_dir/\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600,\n'_num_ps_replicas': 1, '_keep_checkpoint_max': 5, '_task_type': u'worker',\n'_is_chief': False, '_cluster_spec':\n<tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6918438e10>,\n'_model_dir': 'gs://<path>/model_dir/',\n'_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000,\n'_session_config': intra_op_parallelism_threads: 1\ngpu_options {\n}\nallow_soft_placement: true\n, '_tf_random_seed': None, '_environment': u'cloud', '_num_worker_replicas': 1,\n'_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n  per_process_gpu_memory_fraction: 1.0\n  }\n...\n2017-08-01 19:59:26.496208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:00:04.0\nTotal memory: 11.17GiB\nFree memory: 11.09GiB\n2017-08-01 19:59:26.775660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties:\nname: Tesla K80\nmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\npciBusID 0000:00:05.0\nTotal memory: 11.17GiB\nFree memory: 11.10GiB\n...\n2017-08-01 19:59:29.675171: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:8000\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_1/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_2/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_3/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_4/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_5/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage/residual_v1_6/: (?, 16, 32, 32)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_1/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_2/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_3/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_4/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_5/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_1/residual_v1_6/: (?, 32, 16, 16)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/avg_pool/: (?, 32, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_1/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_2/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_3/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_4/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_5/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/stage_2/residual_v1_6/: (?, 64, 8, 8)\nINFO:tensorflow:image after unit resnet/tower_0/global_avg_pool/: (?, 64)\nINFO:tensorflow:image after unit resnet/tower_0/fully_connected/: (?, 11)\nINFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=2; total_num_replicas=2\nINFO:tensorflow:Create CheckpointSaverHook.\n2017-07-31 22:38:04.629150: I\ntensorflow/core/distributed_runtime/master.cc:209] CreateSession still waiting\nfor response from worker: /job:master/replica:0/task:0\n2017-07-31 22:38:09.263492: I\ntensorflow/core/distributed_runtime/master_session.cc:999] Start master\nsession cc58f93b1e259b0c with config:\nintra_op_parallelism_threads: 1\ngpu_options {\nper_process_gpu_memory_fraction: 1\n}\nallow_soft_placement: true\nINFO:tensorflow:loss = 5.82382, step = 0\nINFO:tensorflow:loss = 5.82382, learning_rate = 0.8\nINFO:tensorflow:Average examples/sec: 1116.92 (1116.92), step = 10\nINFO:tensorflow:Average examples/sec: 1233.73 (1377.83), step = 20\nINFO:tensorflow:Average examples/sec: 1485.43 (2509.3), step = 30\nINFO:tensorflow:Average examples/sec: 1680.27 (2770.39), step = 40\nINFO:tensorflow:Average examples/sec: 1825.38 (2788.78), step = 50\nINFO:tensorflow:Average examples/sec: 1929.32 (2697.27), step = 60\nINFO:tensorflow:Average examples/sec: 2015.17 (2749.05), step = 70\nINFO:tensorflow:loss = 37.6272, step = 79 (19.554 sec)\nINFO:tensorflow:loss = 37.6272, learning_rate = 0.8 (19.554 sec)\nINFO:tensorflow:Average examples/sec: 2074.92 (2618.36), step = 80\nINFO:tensorflow:Average examples/sec: 2132.71 (2744.13), step = 90\nINFO:tensorflow:Average examples/sec: 2183.38 (2777.21), step = 100\nINFO:tensorflow:Average examples/sec: 2224.4 (2739.03), step = 110\nINFO:tensorflow:Average examples/sec: 2240.28 (2431.26), step = 120\nINFO:tensorflow:Average examples/sec: 2272.12 (2739.32), step = 130\nINFO:tensorflow:Average examples/sec: 2300.68 (2750.03), step = 140\nINFO:tensorflow:Average examples/sec: 2325.81 (2745.63), step = 150\nINFO:tensorflow:Average examples/sec: 2347.14 (2721.53), step = 160\nINFO:tensorflow:Average examples/sec: 2367.74 (2754.54), step = 170\nINFO:tensorflow:loss = 27.8453, step = 179 (18.893 sec)\n...\n")),(0,o.kt)("h4",{id:"ps"},"PS"),(0,o.kt)("p",null,"Run this on ps:\nThe ps will not do training so most of the arguments won't affect the execution"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"python cifar10_main.py --job-dir=gs://path/model_dir/\n")),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Output:")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"INFO:tensorflow:Using model_dir in TF_CONFIG: gs://path/model_dir/\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 1, '_keep_checkpoint_max': 5, '_task_type': u'ps', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f48f1addf90>, '_model_dir': 'gs://path/model_dir/', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': intra_op_parallelism_threads: 1\ngpu_options {\n}\nallow_soft_placement: true\n, '_tf_random_seed': None, '_environment': u'cloud', '_num_worker_replicas': 1, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n  per_process_gpu_memory_fraction: 1.0\n}\n, '_evaluation_master': '', '_master': u'grpc://master-ip:8000'}\n2017-07-31 22:54:58.928088: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> master-ip:8000}\n2017-07-31 22:54:58.928153: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:8000}\n2017-07-31 22:54:58.928160: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> worker-ip:8000}\n2017-07-31 22:54:58.929873: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:316] Started server with target: grpc://localhost:8000\n")),(0,o.kt)("h2",{id:"visualizing-results-with-tensorboard"},"Visualizing results with TensorBoard"),(0,o.kt)("p",null,"When using Estimators you can also visualize your data in TensorBoard, with no\nchanges in your code. You can use TensorBoard to visualize your TensorFlow\ngraph, plot quantitative metrics about the execution of your graph, and show\nadditional data like images that pass through it."),(0,o.kt)("p",null,'You\'ll see something similar to this if you "point" TensorBoard to the\n',(0,o.kt)("inlineCode",{parentName:"p"},"job dir")," parameter you used to train or evaluate your model."),(0,o.kt)("p",null,"Check TensorBoard during training or after it. Just point TensorBoard to the\nmodel_dir you chose on the previous step."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},'tensorboard --log-dir="<job dir>"\n')),(0,o.kt)("h2",{id:"warnings"},"Warnings"),(0,o.kt)("p",null,"When running ",(0,o.kt)("inlineCode",{parentName:"p"},"cifar10_main.py")," with ",(0,o.kt)("inlineCode",{parentName:"p"},"--sync")," argument you may see an error\nsimilar to:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'File "cifar10_main.py", line 538, in <module>\n    tf.app.run()\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\nFile "cifar10_main.py", line 518, in main\n    hooks), run_config=config)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py", line 210, in run\n    return _execute_schedule(experiment, schedule)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py", line 47, in _execute_schedule\n    return task()\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 501, in train_and_evaluate\n    hooks=self._eval_hooks)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 681, in _call_evaluate\n    hooks=hooks)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 292, in evaluate\n    name=name)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 638, in _evaluate_model\n    features, labels, model_fn_lib.ModeKeys.EVAL)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 545, in _call_model_fn\n    features=features, labels=labels, **kwargs)\nFile "cifar10_main.py", line 331, in _resnet_model_fn\n    gradvars, global_step=tf.train.get_global_step())\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/sync_replicas_optimizer.py", line 252, in apply_gradients\n    variables.global_variables())\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py", line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py", line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)\nFile "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py", line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]\n')),(0,o.kt)("p",null,"This should not affect your training, and should be fixed on the next releases."))}m.isMDXComponent=!0}}]);